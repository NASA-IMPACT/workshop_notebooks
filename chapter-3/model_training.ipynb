{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter-3: Create and train a ML segmentation model using AWS SageMaker\n",
    "\n",
    "The objectives you complete during the course of this chapter introduce you to the process of implementing the SageMaker model training tool. You will engage in this process by completing the objectives listed below.\n",
    "\n",
    "### AWS SageMaker:\n",
    "Amazon SageMaker helps data scientists and developers prepare, build, train, and deploy high-quality machine learning (ML) models quickly by bringing together a broad set of capabilities purpose-built for ML.\n",
    "\n",
    "Simply put, It is a set of cloud-based (specifically, AWS) apps that focus on labeling, training, testing and deploying models.\n",
    "\n",
    "## How it works in context of our HLD problem:\n",
    "\n",
    "### Prepare\n",
    "\n",
    "SageMaker provides in-house labelling tools and data wrangling tools for some common ML workflows. Owing to the spatiotemporal nature of the HLD dataset, we will be skipping this functionality of SageMaker and use the ImageLabeler tool, built by IMPACT, for identifying features and labeling them. This workflow has been covered in Chapter-0 and Chapter-1 of this workshop.\n",
    "\n",
    "### Build, train, and tune\n",
    "\n",
    "SageMaker provides access to cloud-hosted Jupyter notebooks along with pre-built ML models. For our purposes, the model we are using for this demo is the UNet segmentation model (https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/). The architecture is a stack of convolutions followed by de-convolutions. This model assigns a class label to each pixel of the input and gives an output matching the size of the input. The resulting output, once trained with high-latitude dust (HLD) masks, will segment any given image into HLD and non-HLD pixels. We will be covering the process in this chapter (Chapter-3).\n",
    "\n",
    "### Deploy and manage\n",
    "\n",
    "SageMaker provides endpoints to infer from the trained models. This functionality will be showcased in Chapter-4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r src/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import fiona\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import rasterio.features\n",
    "import re\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from io import BytesIO\n",
    "from IPython.display import Image as Display\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Chapter-2: setup access, download, and process data into ML-ready format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_NUMBER = \"350996086543\"\n",
    "ROLE_NAME = \"notebookAccessRole\"\n",
    "ROLE_ARN = f\"arn:aws:iam::{ACCOUNT_NUMBER}:role/{ROLE_NAME}\"\n",
    "SOURCE_BUCKET = \"impact-datashare\"\n",
    "BUCKET_NAME = f\"{ACCOUNT_NUMBER}-model-bucket\"\n",
    "DESTINATION_BUCKET = f\"s3://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a SageMaker session to upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "train_images = sagemaker_session.upload_data(path='data/train')\n",
    "val_images = sagemaker_session.upload_data(path='data/val')\n",
    "test_images = sagemaker_session.upload_data(path='data/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the TensorFlow wrapper provided by SageMaker to train a UNet model\n",
    "\n",
    "The SageMaker Python SDK TensorFlow estimators and models and the SageMaker open-source TensorFlow containers make writing a TensorFlow script and running it in SageMaker easier.\n",
    "\n",
    "We define a SageMaker instance using `sagemaker.tensorflow.Tensorflow` class. \n",
    "\n",
    "- `entry_point` parameter should point to the underlying TensorFlow model implementation.\n",
    "- `source_dir` points to the folder that contains the `entry_point`.\n",
    "- `role` should be given the appropriate notebook access role we created in Chaper-2.\n",
    "- `instance_count`, `instance_type` defines the number of instances and the type of instance of the EC2 instance that will be used for compute.\n",
    "- `output_path` - dictates where the output files from training the model will reside.\n",
    "- `image_uri` should point to the appropriate TensorFlow ECR container image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "keras_metric_definition = [\n",
    "    {\"Name\": \"train:loss\", \"Regex\": \".*loss: ([0-9\\\\.]+) - accuracy: [0-9\\\\.]+.*\"},\n",
    "    {\"Name\": \"train:accuracy\", \"Regex\": \".*loss: [0-9\\\\.]+ - accuracy: ([0-9\\\\.]+).*\"},\n",
    "    {\n",
    "        \"Name\": \"validation:accuracy\",\n",
    "        \"Regex\": \".*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: ([0-9\\\\.]+).*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"validation:loss\",\n",
    "        \"Regex\": \".*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: ([0-9\\\\.]+) - val_accuracy: [0-9\\\\.]+.*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"sec/steps\",\n",
    "        \"Regex\": \".* (\\d+)[mu]s/step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: [0-9\\\\.]+\",\n",
    "    },\n",
    "]\n",
    "\n",
    "LOG_FOLDER = \"tensorboard_logs\"\n",
    "\n",
    "TENSORBOARD_LOGS_PATH = f\"s3://{BUCKET_NAME}/{LOG_FOLDER}/\"\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    entry_point='hld_sagemaker_demo.py',\n",
    "    source_dir=\"/home/ec2-user/SageMaker/workshop_notebooks/chapter-3/src\",\n",
    "    role=ROLE_NAME,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    py_version='py3',\n",
    "    hyperparameters={\"log_dir\": TENSORFLOW_LOGS_PATH},\n",
    "    output_path=DESTINATION_BUCKET,\n",
    "    image_uri='763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.4.1-gpu-py37-cu110-ubuntu18.04',\n",
    "    metric_definition=keras_metric_definition,\n",
    "    distribution={\n",
    "        'parameter_server': {'enabled': True}\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Training the model is as simple as calling estimator.fit() and providing it appropriate arguments that are expected by `hld_sagemaker_demo.py`, which is the entry point for training the custom model (from the previous step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.fit(\n",
    "    {\n",
    "        'train': train_images,\n",
    "        'eval': val_images, \n",
    "        'test': test_images\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach a TensorBoard session\n",
    "\n",
    "TensorBoard in an interactive model training visualization tool. It lets us monitor the training/validation losses over time and gives an idea of how well the model is training. (Since we are passing the logs to S3, we can interact with the logs directly from our local setup.)\n",
    "Here's how you'd connect your TensorBoard to your S3 bucket:\n",
    "1. install TensorBoard version 2.4.1 using `pip install tensorboard==2.4.1`\n",
    "2. run `AWS_REGION=<the region you selected> tensorboard --logdir s3://<your account number>-model-bucket/tensorboard_logs/`\n",
    "3. navigate to localhost:6006 to view the model metrics, model graph timeline, and more.\n",
    "\n",
    "\n",
    "You can also try running it via this very notebook using the following cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The corresponding TensorBoard can be accessed using `https://<your-notebook-instance-name>/proxy/6006/` the https and the trailing spaces are very important.\n",
    "aws_region = sagemaker_session.boto_region_name\n",
    "!AWS_REGION={aws_region} tensorboard --logdir {TENSORBOARD_LOGS_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note the trained model name in the DESTINATION_BUCKETdashboard\n",
    "\n",
    "This will be used in the next chapter to deploy and infer from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": "3.6.13"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
