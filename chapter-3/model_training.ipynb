{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter-3: Create and train a ML Segmentation Model using AWS Sagemaker\n",
    "\n",
    "The objectives you complete during the course of this chapter introduce you to the process of implementing the SageMaker model training tool. You will engage in this process by completing the following objectives:\n",
    "\n",
    "### AWS SageMaker:\n",
    "Amazon SageMaker helps data scientists and developers to prepare, build, train, and deploy high-quality machine learning (ML) models quickly by bringing together a broad set of capabilities purpose-built for ML.\n",
    "\n",
    "Simply put, It is a set of cloud based (specifically, AWS) apps that focus on labeling, training, testing and deploying models.\n",
    "\n",
    "## How it Works in context of our HLD problem:\n",
    "\n",
    "### Prepare:\n",
    "\n",
    "Sagemaker provides in-house labelling tools and data wrangling tools for some common ML workflows. Owing to the spatio temporal nature of the HLD dataset, we will be skipping this functionality of sagemaker and use IMPACT-Built ImageLabeler tool for identifying features and labeling them. This workflow has been covered in Chapter-0 and Chapter-1 of this workshop\n",
    "\n",
    "### Build, Train & Tune:\n",
    "\n",
    "Sagemaker provides access to cloud-hosted jupyter notebooks along with pre-built ML models. For our purposes, The model we are using for this demo is Unet segmentation model (https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/). The architecture is a stack of convolutions followed by de-convolutions. This model assigns a class label to each pixel of the input and gives a output matching the size of the input. The resulting output, once trained with high-latitude dust(HLD) masks, will segment any given image to HLD and non-HLD pixels. we will be covering the process in this chapter (chapter-3).\n",
    "\n",
    "### Deploy and Manage:\n",
    "\n",
    "Sagemaker provides endpoints to infer from the trained models. This functionality will be showcased in Chapter-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r src/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import fiona\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import rasterio.features\n",
    "import re\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from io import BytesIO\n",
    "from IPython.display import Image as Display\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Chapter-2: setup access, download, and process data into ML ready format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_NUMBER = \"350996086543\"\n",
    "ROLE_NAME = \"notebookAccessRole\"\n",
    "ROLE_ARN = f\"arn:aws:iam::{ACCOUNT_NUMBER}:role/{ROLE_NAME}\"\n",
    "SOURCE_BUCKET = \"impact-datashare\"\n",
    "BUCKET_NAME = f\"{ACCOUNT_NUMBER}-model-bucket\"\n",
    "DESTINATION_BUCKET = f\"s3://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a sagemaker session to upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "train_images = sagemaker_session.upload_data(path='data/train')\n",
    "val_images = sagemaker_session.upload_data(path='data/val')\n",
    "test_images = sagemaker_session.upload_data(path='data/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use tensorflow wrapper provided by sagemaker to train a unet model\n",
    "\n",
    "The SageMaker Python SDK TensorFlow estimators and models and the SageMaker open-source TensorFlow containers make writing a TensorFlow script and running it in SageMaker easier.\n",
    "\n",
    "We define a sagemaker instance using `sagemaker.tensorflow.Tensorflow` class. \n",
    "\n",
    "- `entry_point` parameter should point to the underlying tensorflow model implementation.\n",
    "- `source_dir` points to the folder that contains the `entry_point`.\n",
    "- `role` should be given tthe appropriate notebook access role we've created in chaper-2\n",
    "- `instance_count`, `instance_type` defines the number of instances and the type of instance of the EC2 instance that will be used for compute.\n",
    "- `output_path` - dictates where the output files from training the model will reside\n",
    "- `image_uri` should point t the appropriate tensorflow ecr container image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "keras_metric_definition = [\n",
    "    {\"Name\": \"train:loss\", \"Regex\": \".*loss: ([0-9\\\\.]+) - accuracy: [0-9\\\\.]+.*\"},\n",
    "    {\"Name\": \"train:accuracy\", \"Regex\": \".*loss: [0-9\\\\.]+ - accuracy: ([0-9\\\\.]+).*\"},\n",
    "    {\n",
    "        \"Name\": \"validation:accuracy\",\n",
    "        \"Regex\": \".*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: ([0-9\\\\.]+).*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"validation:loss\",\n",
    "        \"Regex\": \".*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: ([0-9\\\\.]+) - val_accuracy: [0-9\\\\.]+.*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"sec/steps\",\n",
    "        \"Regex\": \".* (\\d+)[mu]s/step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: [0-9\\\\.]+\",\n",
    "    },\n",
    "]\n",
    "\n",
    "LOG_FOLDER = \"tensorboard_logs\"\n",
    "\n",
    "TENSORFLOW_LOGS_PATH = f\"s3://{BUCKET_NAME}/{LOG_FOLDER}\"\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    entry_point='hld_sagemaker_demo.py',\n",
    "    source_dir=\"/home/ec2-user/SageMaker/workshop_notebooks/chapter-3/src\",\n",
    "    role=ROLE_NAME,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    py_version='py3',\n",
    "    hyperparameters={\"log_dir\": TENSORFLOW_LOGS_PATH},\n",
    "    output_path=DESTINATION_BUCKET,\n",
    "    image_uri='763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.4.1-gpu-py37-cu110-ubuntu18.04',\n",
    "    metric_definition=keras_metric_definition,\n",
    "    distribution={\n",
    "        'parameter_server': {'enabled': True}\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Training the model is as simple as calling estimator.fit(), providing it appropriate arguments that is expected by `hld_sagemaker_demo.py`, which is the entry point for training the custom model (from the previous step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.fit(\n",
    "    {\n",
    "        'train': train_images,\n",
    "        'eval': val_images, \n",
    "        'test': test_images\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach a Tensorboard session\n",
    "\n",
    "Tensorboard in an interactive model training visualization tool. This lets us monitor the training/validation losses over time and gives an idea of how good the model is training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "aws_region = sagemaker_session.boto_region_name\n",
    "!AWS_REGION={aws_region} tensorboard --logdir {TENSORFLOW_LOGS_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note the trained model name in the DESTINATION_BUCKETdashboard\n",
    "\n",
    "This will be used in the next chapter to deploy and infer from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}