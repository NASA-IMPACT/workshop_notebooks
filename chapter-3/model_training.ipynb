{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter-3: Create and train a ML segmentation model using AWS SageMaker\n",
    "\n",
    "The objectives you complete during the course of this chapter introduce you to the process of implementing the SageMaker model training tool. \n",
    "\n",
    "### AWS SageMaker:\n",
    "Amazon SageMaker helps data scientists and developers prepare, build, train, and deploy high-quality machine learning (ML) models quickly by bringing together a broad set of capabilities purpose-built for ML.\n",
    "\n",
    "Simply put, It is a set of cloud-based (specifically, AWS) apps that focus on labeling, training, testing and deploying models.\n",
    "\n",
    "## How it works in context of our HLD problem:\n",
    "\n",
    "### Prepare\n",
    "\n",
    "SageMaker provides in-house labelling tools and data wrangling tools for some common ML workflows. Owing to the spatiotemporal nature of the HLD dataset, we will be skipping this functionality of SageMaker and use the ImageLabeler tool, built by IMPACT, for identifying features and labeling them. This workflow has been covered in Chapter-0 and Chapter-1 of this workshop.\n",
    "\n",
    "### Build, train, and tune\n",
    "\n",
    "SageMaker provides access to cloud-hosted Jupyter notebooks along with pre-built ML models. For our purposes, the model we are using for this demo is the UNet segmentation model (https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/). The architecture is a stack of convolutions followed by de-convolutions. This model assigns a class label to each pixel of the input and gives an output matching the size of the input. The resulting output, once trained with high-latitude dust (HLD) masks, will segment any given image into HLD and non-HLD pixels. We will be covering the process in this chapter (Chapter-3).\n",
    "\n",
    "### Deploy and manage\n",
    "\n",
    "SageMaker provides endpoints to infer from the trained models. This functionality will be showcased in Chapter-4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from -r src/requirements.txt (line 1)) (1.17.79)\n",
      "Requirement already satisfied: fiona in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from -r src/requirements.txt (line 2)) (1.8.20)\n",
      "Requirement already satisfied: imgaug in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from -r src/requirements.txt (line 3)) (0.4.0)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from -r src/requirements.txt (line 4)) (3.3.4)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from -r src/requirements.txt (line 5)) (1.19.5)\n",
      "Requirement already satisfied: opencv-python-headless in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from -r src/requirements.txt (line 6)) (4.5.2.52)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from -r src/requirements.txt (line 7)) (1.1.5)\n",
      "Requirement already satisfied: rasterio in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from -r src/requirements.txt (line 8)) (1.2.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from -r src/requirements.txt (line 9)) (2.25.1)\n",
      "Requirement already satisfied: sklearn in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from -r src/requirements.txt (line 10)) (0.0)\n",
      "Requirement already satisfied: tensorflow==2.4.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from -r src/requirements.txt (line 11)) (2.4.1)\n",
      "Requirement already satisfied: tensorboard<2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from -r src/requirements.txt (line 12)) (2.3.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (1.1.2)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (1.32.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (2.10.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (0.12.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (1.15.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (0.3.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (3.7.4.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (2.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (3.15.2)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (3.3.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (1.12.1)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.4.1->-r src/requirements.txt (line 11)) (0.36.2)\n",
      "Collecting tensorboard<2.5\n",
      "  Using cached tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<2.5->-r src/requirements.txt (line 12)) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<2.5->-r src/requirements.txt (line 12)) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<2.5->-r src/requirements.txt (line 12)) (49.6.0.post20210108)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<2.5->-r src/requirements.txt (line 12)) (1.30.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<2.5->-r src/requirements.txt (line 12)) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<2.5->-r src/requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->-r src/requirements.txt (line 9)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->-r src/requirements.txt (line 9)) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->-r src/requirements.txt (line 9)) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests->-r src/requirements.txt (line 9)) (1.26.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.5->-r src/requirements.txt (line 12)) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.5->-r src/requirements.txt (line 12)) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.5->-r src/requirements.txt (line 12)) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.5->-r src/requirements.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.5->-r src/requirements.txt (line 12)) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.5->-r src/requirements.txt (line 12)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.5->-r src/requirements.txt (line 12)) (3.1.0)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from boto3->-r src/requirements.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from boto3->-r src/requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.79 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from boto3->-r src/requirements.txt (line 1)) (1.20.79)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.79->boto3->-r src/requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from fiona->-r src/requirements.txt (line 2)) (0.7.2)\n",
      "Requirement already satisfied: click>=4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from fiona->-r src/requirements.txt (line 2)) (7.1.2)\n",
      "Requirement already satisfied: munch in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from fiona->-r src/requirements.txt (line 2)) (2.5.0)\n",
      "Requirement already satisfied: attrs>=17 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from fiona->-r src/requirements.txt (line 2)) (20.3.0)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from fiona->-r src/requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: Shapely in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from imgaug->-r src/requirements.txt (line 3)) (1.7.1)\n",
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from imgaug->-r src/requirements.txt (line 3)) (4.5.1.48)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from imgaug->-r src/requirements.txt (line 3)) (8.1.0)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from imgaug->-r src/requirements.txt (line 3)) (0.16.2)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from imgaug->-r src/requirements.txt (line 3)) (1.5.3)\n",
      "Requirement already satisfied: imageio in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from imgaug->-r src/requirements.txt (line 3)) (2.9.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from scikit-image>=0.14.2->imgaug->-r src/requirements.txt (line 3)) (2.5)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from scikit-image>=0.14.2->imgaug->-r src/requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from matplotlib->-r src/requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from matplotlib->-r src/requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from matplotlib->-r src/requirements.txt (line 4)) (2.4.7)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug->-r src/requirements.txt (line 3)) (4.4.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from pandas->-r src/requirements.txt (line 7)) (2021.1)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from rasterio->-r src/requirements.txt (line 8)) (1.4.7)\n",
      "Requirement already satisfied: affine in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from rasterio->-r src/requirements.txt (line 8)) (2.3.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from sklearn->-r src/requirements.txt (line 10)) (0.24.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.5->-r src/requirements.txt (line 12)) (3.4.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from scikit-learn->sklearn->-r src/requirements.txt (line 10)) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from scikit-learn->sklearn->-r src/requirements.txt (line 10)) (2.1.0)\n",
      "Installing collected packages: tensorboard\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.3.0\n",
      "    Uninstalling tensorboard-2.3.0:\n",
      "      Successfully uninstalled tensorboard-2.3.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-serving-api 2.1.0 requires tensorflow~=2.1.0, but you have tensorflow 2.4.1 which is incompatible.\n",
      "tensorflow-cpu 2.1.3 requires gast==0.2.2, but you have gast 0.3.3 which is incompatible.\n",
      "tensorflow-cpu 2.1.3 requires keras-preprocessing==1.1.0, but you have keras-preprocessing 1.1.2 which is incompatible.\n",
      "tensorflow-cpu 2.1.3 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.19.5 which is incompatible.\n",
      "tensorflow-cpu 2.1.3 requires tensorboard<2.2.0,>=2.1.0, but you have tensorboard 2.4.1 which is incompatible.\n",
      "tensorflow-cpu 2.1.3 requires tensorflow-estimator<2.2.0,>=2.1.0rc0, but you have tensorflow-estimator 2.4.0 which is incompatible.\u001b[0m\n",
      "Successfully installed tensorboard-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r src/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import fiona\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import rasterio.features\n",
    "import re\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from io import BytesIO\n",
    "from IPython.display import Image as Display\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Chapter-2: setup access, download, and process data into ML-ready format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_NUMBER = <your account number>\n",
    "ROLE_NAME = \"notebookAccessRole\"\n",
    "ROLE_ARN = f\"arn:aws:iam::{ACCOUNT_NUMBER}:role/{ROLE_NAME}\"\n",
    "SOURCE_BUCKET = \"impact-datashare\"\n",
    "BUCKET_NAME = f\"{ACCOUNT_NUMBER}-model-bucket\"\n",
    "DESTINATION_BUCKET = f\"s3://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a SageMaker session to upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "train_images = sagemaker_session.upload_data(path='data/train', bucket=BUCKET_NAME, key_prefix='data/train')\n",
    "val_images = sagemaker_session.upload_data(path='data/val', bucket=BUCKET_NAME, key_prefix='data/val')\n",
    "test_images = sagemaker_session.upload_data(path='data/test', bucket=BUCKET_NAME, key_prefix='data/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning\n",
    "Deep learning refers to neural networks with multiple hidden layers that can learn increasingly abstract representations of the input data.\n",
    "\n",
    "deep learning has led to major advances in computer vision. We’re now able to classify images, find objects in them, and even label them with captions. To do so, deep neural networks with many hidden layers can sequentially learn more complex features from the raw input image:\n",
    "* The first hidden layers might only learn local edge patterns.\n",
    "* Then, each subsequent layer (or filter) learns more complex representations.\n",
    "* Finally, the last layer can classify the image as a cat or kangaroo.\n",
    "These types of deep neural networks are called Convolutional Neural Networks.\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "Convolutional Neural Networks (CNN’s) are multi-layer neural networks (sometimes up to 17 or more layers) that assume the input data to be images.\n",
    "\n",
    "<img src=\"Feature_maps.png\">\n",
    "\n",
    "By making this requirement, CNN's can drastically reduce the number of parameters that need to be tuned. Therefore, CNN's can efficiently handle the high dimensionality of raw images.\n",
    "\n",
    "There are multitude of different neural network architectures that use CNN that are used for various tasks. For Image segmeenttation task, we use U-Net model:\n",
    "\n",
    "## U-Net Segmentation model\n",
    "\n",
    "The model we are using for this demo is the U-Net segmentation model (https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/). The architecture is a stack of convolutions followed by de-convolutions that gives it's U-shape. \n",
    "<img src=\"u-net-architecture.png\">\n",
    "\n",
    "This model assigns a class label to each pixel of the input and gives an output matching the size of the input. The resulting output, once trained with high-latitude dust (HLD) masks, will segment any given image into HLD and non-HLD pixels.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras: A Deep Learning Framework\n",
    "Keras is a library for deep learning in Python. Its minimalistic, modular approach makes it easy to get deep neural networks up and running. You can read more about it here: https://keras.io/\n",
    "\n",
    "Assuming keras is installed in your python environment, The main usage of the library is listed as follows:\n",
    "\n",
    "### import keras modules\n",
    "\n",
    "```\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "```\n",
    "### Preprocess / Load Images.\n",
    "\n",
    "Using Image Libraries and preprocessing, convert images into numpy arrays.\n",
    "\n",
    "we use keras sequence library (https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence) to load a subset of input images in memory at a time and process in batches. This makes sure we are not running out of memory trying to load all images at once. imgaug library (https://github.com/aleju/imgaug) is used to augment images by translations and introducing random noise to inclrease the variability in input images and help with model generalization.\n",
    "\n",
    "### Define model architecture\n",
    "\n",
    "We define a neural network model as a set of keras layer objects, starting from Input to Output, and hidden layers in between. Here are some example models: https://keras.io/examples/\n",
    "\n",
    "### Add Regularization methods to prevent overfitting\n",
    "Overfitting is a case when the model learns too much of training data that it fails to replicate the performance in real-world (test) data. regularization techniques are measures used to prevent this case.\n",
    "#### Dropouts\n",
    "This is a method for regularizing our model in order to prevent overfitting. You can read more about it here.\n",
    "#### MaxPooling\n",
    "MaxPooling2D is a way to reduce the number of parameters in our model by sliding a 2x2 pooling filter across the previous layer and taking the max of the 4 values in the 2x2 filter.\n",
    "\n",
    "#### BatchNormalization\n",
    "\n",
    "Batch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch. This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs required to train deep networks.\n",
    "\n",
    "### Compile model with loss metric\n",
    "\n",
    "When we compile the model, we declare the loss function and the optimizer (SGD, Adam, etc.)\n",
    "Keras has a variety of [loss functions](https://keras.io/api/losses/) and out-of-the-box [optimizers](https://keras.io/api/optimizers/) to choose from.\n",
    "```\n",
    "Loss function dictates how far the model estimate is from the actual output (truth value), and the optimizer makes adjustments to the model variables so that the estimate is closer to the actual output.\n",
    "\n",
    "Model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=None,\n",
    "    metrics=None,\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    "    steps_per_execution=None,\n",
    "    **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "### Define Callbacks\n",
    "Callbacks are pieces of code that get executed every time the model trains through one pass of all available input images. This is particularly useful functionality provided by keras to do various tasks such as stopping training if the model does not improve significantly, saving the weights of the best model only, and plotting training graph to better understand how the model learns in training phase.\n",
    "\n",
    " ### training the model with the generators\n",
    " \n",
    " Finally, training the model is as simple as calling `model.fit()` method. \n",
    "\n",
    "```\n",
    "Model.fit(\n",
    "    x=None,\n",
    "    y=None,\n",
    "    batch_size=None,\n",
    "    epochs=1,\n",
    "    verbose=\"auto\",\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    validation_data=None,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=None,\n",
    "    validation_batch_size=None,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    ")\n",
    "``` \n",
    " some notes:\n",
    "\n",
    "'steps_per_epoch' defines the number of times the generator should be called for each epoch. this number is the number of input samples (54) divided by the batch_size (4) ~= 13. similrly, validation_step is num of images in validation split (38) divided by batch_size ~= 10\n",
    "\n",
    "'epochs' just need to be sufficiently large, since we are using EarlyStopping callback to preemptively stop model training if the loss does not improve for several epochs\n",
    "\n",
    "### Test Model:\n",
    "\n",
    "Predictions can be made on any input image by calling `model.predict()` with the list of input images to predict.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the TensorFlow wrapper provided by SageMaker to train a UNet model\n",
    "\n",
    "Tensorflow is a low-level deeplearning library used by keras developed and maintained by google.\n",
    "\n",
    "The SageMaker Python SDK TensorFlow estimators and models and the SageMaker open-source TensorFlow containers make writing a TensorFlow script and running it in SageMaker easier.\n",
    "\n",
    "We define a SageMaker instance using `sagemaker.tensorflow.Tensorflow` class. \n",
    "\n",
    "- `entry_point` parameter should point to the underlying TensorFlow model implementation.\n",
    "- `source_dir` points to the folder that contains the `entry_point`.\n",
    "- `role` should be given the appropriate notebook access role we created in Chaper-2.\n",
    "- `instance_count`, `instance_type` defines the number of instances and the type of instance of the EC2 instance that will be used for compute.\n",
    "- `output_path` - dictates where the output files from training the model will reside.\n",
    "- `image_uri` should point to the appropriate TensorFlow ECR container image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "keras_metric_definition = [\n",
    "    {\"Name\": \"train:loss\", \"Regex\": \".*loss: ([0-9\\\\.]+) - accuracy: [0-9\\\\.]+.*\"},\n",
    "    {\"Name\": \"train:accuracy\", \"Regex\": \".*loss: [0-9\\\\.]+ - accuracy: ([0-9\\\\.]+).*\"},\n",
    "    {\n",
    "        \"Name\": \"validation:accuracy\",\n",
    "        \"Regex\": \".*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: ([0-9\\\\.]+).*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"validation:loss\",\n",
    "        \"Regex\": \".*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: ([0-9\\\\.]+) - val_accuracy: [0-9\\\\.]+.*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"sec/steps\",\n",
    "        \"Regex\": \".* (\\d+)[mu]s/step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: [0-9\\\\.]+\",\n",
    "    },\n",
    "]\n",
    "\n",
    "LOG_FOLDER = \"tensorboard_logs\"\n",
    "\n",
    "TENSORBOARD_LOGS_PATH = f\"s3://{BUCKET_NAME}/{LOG_FOLDER}/\"\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    entry_point='hld_sagemaker_demo.py',\n",
    "    source_dir=\"/home/ec2-user/SageMaker/workshop_notebooks/chapter-3/src\",\n",
    "    role=ROLE_NAME,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    py_version='py3',\n",
    "    hyperparameters={\"log_dir\": TENSORBOARD_LOGS_PATH, 'epochs': 35, 'batch_size': 20, 'learning_rate': 0.01},\n",
    "    output_path=DESTINATION_BUCKET,\n",
    "    image_uri='763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.4.1-gpu-py37-cu110-ubuntu18.04',\n",
    "    metric_definition=keras_metric_definition,\n",
    "    distribution={\n",
    "        'parameter_server': {'enabled': True}\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Training the model is as simple as calling estimator.fit() and providing it appropriate arguments that are expected by `hld_sagemaker_demo.py`, which is the entry point for training the custom model (from the previous step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-02 17:54:56 Starting - Starting the training job...\n",
      "2021-06-02 17:54:58 Starting - Launching requested ML instancesProfilerReport-1622656495: InProgress\n",
      "......\n",
      "2021-06-02 17:56:12 Starting - Preparing the instances for training.........\n",
      "2021-06-02 17:57:52 Downloading - Downloading input data...\n",
      "2021-06-02 17:58:12 Training - Downloading the training image...........\u001b[34m2021-06-02 17:59:59.764654: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-06-02 17:59:59.769554: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-06-02 17:59:59.880204: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\u001b[0m\n",
      "\u001b[34m2021-06-02 17:59:59.998353: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-06-02 18:00:03,931 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-06-02 18:00:04,368 sagemaker-training-toolkit INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 -m pip install . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.17.69)\u001b[0m\n",
      "\u001b[34mCollecting fiona\n",
      "  Downloading Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4 MB)\u001b[0m\n",
      "\u001b[34mCollecting imgaug\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\u001b[0m\n",
      "\u001b[34mCollecting matplotlib\n",
      "  Downloading matplotlib-3.4.2-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.19.5)\u001b[0m\n",
      "\u001b[34mCollecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (1.1.0)\u001b[0m\n",
      "\u001b[34mCollecting rasterio\n",
      "  Downloading rasterio-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (2.24.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sklearn in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (0.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow==2.4.1\n",
      "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\u001b[0m\n",
      "\n",
      "2021-06-02 18:00:13 Training - Training image download completed. Training in progress.\u001b[34mCollecting tensorboard<2.5\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (1.32.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (0.36.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (3.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (3.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (0.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (2.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (1.6.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (3.7.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (2.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (1.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.4.1->-r requirements.txt (line 11)) (1.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.5->-r requirements.txt (line 12)) (1.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.5->-r requirements.txt (line 12)) (3.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.5->-r requirements.txt (line 12)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.5->-r requirements.txt (line 12)) (1.30.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.5->-r requirements.txt (line 12)) (56.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.5->-r requirements.txt (line 12)) (0.4.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->-r requirements.txt (line 9)) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->-r requirements.txt (line 9)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->-r requirements.txt (line 9)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->-r requirements.txt (line 9)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.5->-r requirements.txt (line 12)) (4.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.5->-r requirements.txt (line 12)) (4.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.5->-r requirements.txt (line 12)) (0.2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.5->-r requirements.txt (line 12)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.5->-r requirements.txt (line 12)) (4.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.5->-r requirements.txt (line 12)) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.5->-r requirements.txt (line 12)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.21.0,>=1.20.69 in /usr/local/lib/python3.7/site-packages (from boto3->-r requirements.txt (line 1)) (1.20.69)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3->-r requirements.txt (line 1)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/site-packages (from boto3->-r requirements.txt (line 1)) (0.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/site-packages (from botocore<1.21.0,>=1.20.69->boto3->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/site-packages (from fiona->-r requirements.txt (line 2)) (21.2.0)\u001b[0m\n",
      "\u001b[34mCollecting click>=4.0\n",
      "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mCollecting cligj>=0.5\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting click-plugins>=1.0\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting munch\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting imageio\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\u001b[0m\n",
      "\u001b[34mCollecting Shapely\n",
      "  Downloading Shapely-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /usr/local/lib/python3.7/site-packages (from imgaug->-r requirements.txt (line 3)) (1.5.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow in /usr/local/lib/python3.7/site-packages (from imgaug->-r requirements.txt (line 3)) (8.2.0)\u001b[0m\n",
      "\u001b[34mCollecting scikit-image>=0.14.2\n",
      "  Downloading scikit_image-0.18.1-cp37-cp37m-manylinux1_x86_64.whl (29.2 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/site-packages (from imgaug->-r requirements.txt (line 3)) (4.3.0.36)\u001b[0m\n",
      "\u001b[34mCollecting networkx>=2.0\n",
      "  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34mCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.4.8-py3-none-any.whl (165 kB)\u001b[0m\n",
      "\u001b[34mCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 4)) (2.4.7)\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting decorator<5,>=4.3\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 7)) (2021.1)\u001b[0m\n",
      "\u001b[34mCollecting snuggs>=1.4.1\n",
      "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting affine\n",
      "  Downloading affine-2.3.0-py2.py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (from sklearn->-r requirements.txt (line 10)) (0.23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.5->-r requirements.txt (line 12)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 10)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 10)) (1.0.1)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: hld-sagemaker-demo\n",
      "  Building wheel for hld-sagemaker-demo (setup.py): started\n",
      "  Building wheel for hld-sagemaker-demo (setup.py): finished with status 'done'\n",
      "  Created wheel for hld-sagemaker-demo: filename=hld_sagemaker_demo-1.0-py3-none-any.whl size=1119 sha256=9f02400dd26463d2b1cfa0062ab5b1c3a51c64ec0e7f0fddb8e04c3bc845c788\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-03ywxgn2/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built hld-sagemaker-demo\u001b[0m\n",
      "\u001b[34mInstalling collected packages: kiwisolver, decorator, cycler, tifffile, PyWavelets, networkx, matplotlib, imageio, click, tensorboard, snuggs, Shapely, scikit-image, munch, cligj, click-plugins, affine, tensorflow, rasterio, opencv-python-headless, imgaug, hld-sagemaker-demo, fiona\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed PyWavelets-1.1.1 Shapely-1.7.1 affine-2.3.0 click-8.0.1 click-plugins-1.1.1 cligj-0.7.2 cycler-0.10.0 decorator-4.4.2 fiona-1.8.20 hld-sagemaker-demo-1.0 imageio-2.9.0 imgaug-0.4.0 kiwisolver-1.3.1 matplotlib-3.4.2 munch-2.5.0 networkx-2.5.1 opencv-python-headless-4.5.2.52 rasterio-1.2.4 scikit-image-0.18.1 snuggs-1.4.7 tensorboard-2.4.1 tensorflow-2.4.1 tifffile-2021.4.8\n",
      "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.1.1; however, version 21.1.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-06-02 18:00:47,118 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"eval\": \"/opt/ml/input/data/eval\",\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"log_dir\": \"s3://350996086543-model-bucket/tensorboard_logs/\",\n",
      "        \"model_dir\": \"s3://350996086543-model-bucket/tensorflow-training-2021-06-02-17-54-55-680/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"eval\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2021-06-02-17-54-55-680\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://350996086543-model-bucket/tensorflow-training-2021-06-02-17-54-55-680/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"hld_sagemaker_demo\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"hld_sagemaker_demo.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"log_dir\":\"s3://350996086543-model-bucket/tensorboard_logs/\",\"model_dir\":\"s3://350996086543-model-bucket/tensorflow-training-2021-06-02-17-54-55-680/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=hld_sagemaker_demo.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"eval\",\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=hld_sagemaker_demo\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://350996086543-model-bucket/tensorflow-training-2021-06-02-17-54-55-680/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"eval\":\"/opt/ml/input/data/eval\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"log_dir\":\"s3://350996086543-model-bucket/tensorboard_logs/\",\"model_dir\":\"s3://350996086543-model-bucket/tensorflow-training-2021-06-02-17-54-55-680/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2021-06-02-17-54-55-680\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://350996086543-model-bucket/tensorflow-training-2021-06-02-17-54-55-680/source/sourcedir.tar.gz\",\"module_name\":\"hld_sagemaker_demo\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"hld_sagemaker_demo.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--log_dir\",\"s3://350996086543-model-bucket/tensorboard_logs/\",\"--model_dir\",\"s3://350996086543-model-bucket/tensorflow-training-2021-06-02-17-54-55-680/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_EVAL=/opt/ml/input/data/eval\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_LOG_DIR=s3://350996086543-model-bucket/tensorboard_logs/\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://350996086543-model-bucket/tensorflow-training-2021-06-02-17-54-55-680/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 -m hld_sagemaker_demo --log_dir s3://350996086543-model-bucket/tensorboard_logs/ --model_dir s3://350996086543-model-bucket/tensorflow-training-2021-06-02-17-54-55-680/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2 0 /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m1 0 /opt/ml/input/data/eval\u001b[0m\n",
      "\u001b[34mModel: \"model\"\u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                    Output Shape         Param #     Connected to                     \u001b[0m\n",
      "\u001b[34m==================================================================================================\u001b[0m\n",
      "\u001b[34minput_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d (Conv2D)                 (None, 256, 256, 24) 672         input_1[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization (BatchNorma (None, 256, 256, 24) 96          conv2d[0][0]                     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_1 (Conv2D)               (None, 256, 256, 24) 5208        batch_normalization[0][0]        \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_1 (BatchNor (None, 256, 256, 24) 96          conv2d_1[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_2 (Conv2D)               (None, 256, 256, 24) 5208        batch_normalization_1[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d (MaxPooling2D)    (None, 128, 128, 24) 0           conv2d_2[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_2 (BatchNor (None, 128, 128, 24) 96          max_pooling2d[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_3 (Conv2D)               (None, 128, 128, 24) 5208        batch_normalization_2[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_3 (BatchNor (None, 128, 128, 24) 96          conv2d_3[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_4 (Conv2D)               (None, 128, 128, 24) 5208        batch_normalization_3[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_4 (BatchNor (None, 128, 128, 24) 96          conv2d_4[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_5 (Conv2D)               (None, 128, 128, 24) 5208        batch_normalization_4[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 24)   0           conv2d_5[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_5 (BatchNor (None, 64, 64, 24)   96          max_pooling2d_1[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_6 (Conv2D)               (None, 64, 64, 24)   5208        batch_normalization_5[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_6 (BatchNor (None, 64, 64, 24)   96          conv2d_6[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_7 (Conv2D)               (None, 64, 64, 24)   5208        batch_normalization_6[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_7 (BatchNor (None, 64, 64, 24)   96          conv2d_7[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_8 (Conv2D)               (None, 64, 64, 24)   5208        batch_normalization_7[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 24)   0           conv2d_8[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_8 (BatchNor (None, 32, 32, 24)   96          max_pooling2d_2[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_9 (Conv2D)               (None, 32, 32, 24)   5208        batch_normalization_8[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_9 (BatchNor (None, 32, 32, 24)   96          conv2d_9[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_10 (Conv2D)              (None, 32, 32, 24)   5208        batch_normalization_9[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_10 (BatchNo (None, 32, 32, 24)   96          conv2d_10[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_transpose (Conv2DTranspo (None, 64, 64, 24)   5208        batch_normalization_10[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcatenate (Concatenate)       (None, 64, 64, 48)   0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_7[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_11 (BatchNo (None, 64, 64, 48)   192         concatenate[0][0]                \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_11 (Conv2D)              (None, 64, 64, 32)   13856       batch_normalization_11[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_12 (BatchNo (None, 64, 64, 32)   128         conv2d_11[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_12 (Conv2D)              (None, 64, 64, 24)   6936        batch_normalization_12[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_13 (BatchNo (None, 64, 64, 24)   96          conv2d_12[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_transpose_1 (Conv2DTrans (None, 128, 128, 24) 5208        batch_normalization_13[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcatenate_1 (Concatenate)     (None, 128, 128, 48) 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_4[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_14 (BatchNo (None, 128, 128, 48) 192         concatenate_1[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_13 (Conv2D)              (None, 128, 128, 32) 13856       batch_normalization_14[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_15 (BatchNo (None, 128, 128, 32) 128         conv2d_13[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_14 (Conv2D)              (None, 128, 128, 24) 6936        batch_normalization_15[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_16 (BatchNo (None, 128, 128, 24) 96          conv2d_14[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_transpose_2 (Conv2DTrans (None, 256, 256, 24) 5208        batch_normalization_16[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcatenate_2 (Concatenate)     (None, 256, 256, 48) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_17 (BatchNo (None, 256, 256, 48) 192         concatenate_2[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_15 (Conv2D)              (None, 256, 256, 32) 13856       batch_normalization_17[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_18 (BatchNo (None, 256, 256, 32) 128         conv2d_15[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_16 (Conv2D)              (None, 256, 256, 24) 6936        batch_normalization_18[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_17 (Conv2D)              (None, 256, 256, 1)  25          conv2d_16[0][0]                  \u001b[0m\n",
      "\u001b[34m==================================================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 132,985\u001b[0m\n",
      "\u001b[34mTrainable params: 131,881\u001b[0m\n",
      "\u001b[34mNon-trainable params: 1,104\u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mEpoch 1/5\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 23s - loss: 0.8331 - accuracy: 0.5189#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - ETA: 0s - loss: 0.7980 - accuracy: 0.5379 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 28s 5s/step - loss: 0.7864 - accuracy: 0.5442 - val_loss: 0.6334 - val_accuracy: 0.6182\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00001: val_loss improved from inf to 0.63345, saving model to s3://350996086543-model-bucket/tensorflow-training-2021-06-02-17-54-55-680/model\u001b[0m\n",
      "\u001b[34mEpoch 2/5\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.6602 - accuracy: 0.6130#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - ETA: 0s - loss: 0.6597 - accuracy: 0.6174#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 1s 535ms/step - loss: 0.6596 - accuracy: 0.6189 - val_loss: 0.6236 - val_accuracy: 0.6787\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00002: val_loss improved from 0.63345 to 0.62363, saving model to s3://350996086543-model-bucket/tensorflow-training-2021-06-02-17-54-55-680/model\u001b[0m\n",
      "\u001b[34mEpoch 3/5\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.5579 - accuracy: 0.7103#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.7041#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 1s 487ms/step - loss: 0.5802 - accuracy: 0.7021 - val_loss: 0.5893 - val_accuracy: 0.6939\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00003: val_loss improved from 0.62363 to 0.58935, saving model to s3://350996086543-model-bucket/tensorflow-training-2021-06-02-17-54-55-680/model\u001b[0m\n",
      "\u001b[34mEpoch 4/5\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.6538 - accuracy: 0.6909#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - ETA: 0s - loss: 0.6323 - accuracy: 0.6937#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 1s 438ms/step - loss: 0.6251 - accuracy: 0.6947 - val_loss: 0.5790 - val_accuracy: 0.6964\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00004: val_loss improved from 0.58935 to 0.57900, saving model to s3://350996086543-model-bucket/tensorflow-training-2021-06-02-17-54-55-680/model\u001b[0m\n",
      "\u001b[34mEpoch 5/5\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 0s - loss: 0.5684 - accuracy: 0.6886#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - ETA: 0s - loss: 0.5856 - accuracy: 0.6853#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 1s 513ms/step - loss: 0.5913 - accuracy: 0.6842 - val_loss: 0.6119 - val_accuracy: 0.7143\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00005: val_loss did not improve from 0.57900\u001b[0m\n",
      "\u001b[34ms3://350996086543-model-bucket/tensorflow-training-2021-06-02-17-54-55-680/model/1\u001b[0m\n",
      "\n",
      "2021-06-02 18:02:27 Uploading - Uploading generated training model\u001b[34m2021-06-02 18:01:24.950621: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-06-02 18:02:24,272 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-06-02 18:02:53 Completed - Training job completed\n",
      "ProfilerReport-1622656495: NoIssuesFound\n",
      "Training seconds: 283\n",
      "Billable seconds: 283\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(\n",
    "    {\n",
    "        'train': train_images,\n",
    "        'eval': val_images, \n",
    "        'test': test_images\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach a TensorBoard session\n",
    "\n",
    "TensorBoard in an interactive model training visualization tool. It lets us monitor the training/validation losses over time and gives an idea of how well the model is training. (Since we are passing the logs to S3, we can interact with the logs directly from our local setup.)\n",
    "Here's how you'd connect your TensorBoard to your S3 bucket:\n",
    "1. install TensorBoard version 2.4.1 using `pip install tensorboard==2.4.1`\n",
    "2. run `AWS_REGION=<the region you selected> tensorboard --logdir s3://<your account number>-model-bucket/tensorboard_logs/`\n",
    "3. navigate to localhost:6006 to view the model metrics, model graph timeline, and more.\n",
    "\n",
    "\n",
    "You can also try running it via this very notebook using the following cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The corresponding TensorBoard can be accessed using `https://<your-notebook-instance-name>/proxy/6006/` the https and the trailing spaces are very important.\n",
    "aws_region = sagemaker_session.boto_region_name\n",
    "!AWS_REGION={aws_region} tensorboard --logdir {TENSORBOARD_LOGS_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note the trained model name in the DESTINATION_BUCKET dashboard\n",
    "\n",
    "This will be used in the next chapter to deploy and infer from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}