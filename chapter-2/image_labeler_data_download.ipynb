{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter-2: Prepare Training Data\n",
    "\n",
    "In this chapter, we will go through how to download HLD data from s3 buckets, preprocess them, and split them for training a ML model.\n",
    "After completing this chapter, you will have familiarized with the process of transfering images into ImageLabeler for analysis. The following objectives are part of this chapter:\n",
    "- Review and execute code that will download pre-prepared high latitude dust data from an S3 bucket.\n",
    "- Learn the types of constant variables and the format of each, which are needed to complete the data download.\n",
    "- Review and execute the code necessary to prepare the environment for data transfer.\n",
    "- Review and execute code that generates helper methods that facilitate the download and the visualization of the data.\n",
    "- Review and execute code that checks the downloaded data and prepares the splits.\n",
    "\n",
    "The flow of the process is illustrated in this diagram:\n",
    "\n",
    "<img src=\"workflow.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../chapter-3/src/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import fiona\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import rasterio.features\n",
    "import cv2\n",
    "import numpy.ma as ma\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from io import BytesIO\n",
    "from IPython.display import Image as Display\n",
    "from PIL import Image\n",
    "from rasterio.warp import calculate_default_transform\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Constant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_NUMBER = \"350996086543\"\n",
    "ROLE_NAME = \"notebookAccessRole\"\n",
    "ROLE_ARN = f\"arn:aws:iam::{ACCOUNT_NUMBER}:role/{ROLE_NAME}\"\n",
    "SOURCE_BUCKET = \"impact-datashare\" # identifier for IMPACT's s3 buckets\n",
    "\n",
    "# NOTE: Use image_url function above to create a valid url, if the shapefile generation was not done in Aqua, TrueColor \n",
    "DATA_FOLDER = \"../chapter-3/data\"\n",
    "EVENT = \"hld-labeled\"\n",
    "IMAGE_FOLDER = \"images\"\n",
    "SHAPEFILE_FOLDER = \"shapefiles\"\n",
    "URL = \"https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi?SERVICE=WMS&REQUEST=GetMap&layers=MODIS_Aqua_CorrectedReflectance_TrueColor&version=1.3.0&crs=EPSG:4326&transparent=false&width={}&height={}&bbox={}&format=image/tiff&time={}\"\n",
    "KM_PER_DEG_AT_EQ = 111.\n",
    "RESOLUTION = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment for Notebook Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assumed_role_session():\n",
    "    \"\"\" Assume the \"notebookAccessRole\" role we created using AWS CDK in chapter-0\"\"\"\n",
    "    client = boto3.client('sts')\n",
    "    creds = client.assume_role(\n",
    "        RoleArn=ROLE_ARN,\n",
    "        RoleSessionName=ROLE_NAME\n",
    "    )['Credentials']\n",
    "    return boto3.session.Session(\n",
    "        aws_access_key_id=creds['AccessKeyId'],\n",
    "        aws_secret_access_key=creds['SecretAccessKey'],\n",
    "        aws_session_token=creds['SessionToken'],\n",
    "        region_name='us-east-1'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Delete folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(foldername):\n",
    "    \"\"\"\n",
    "    creates folders if 'foldername' doesn't exist\n",
    "    \"\"\"\n",
    "    if os.path.exists(foldername):\n",
    "        print(f\"'{foldername}' folder already exists.\")\n",
    "        return\n",
    "    os.makedirs(foldername)\n",
    "    print(f\"Created folder: {foldername}\")\n",
    "\n",
    "    \n",
    "def delete_folder(foldername):\n",
    "    \"\"\"deletes folder and its contents \"\"\"\n",
    "    if os.path.exists(foldername):\n",
    "        shutil.rmtree(foldername) \n",
    "    else:\n",
    "        print(f\"Folder {foldername} doesn't exist.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Querying Operations\n",
    "\n",
    "These set of helper functions are used to query gibs for MODIS imagery with requiired query parameters, calculate the image dimensions of a given extent,and convert shapefiles into rasters of 0's and 1's corresponding to the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_url(query_date, bbox, sensor, product, width, height):\n",
    "    \"\"\"create a url to return an image based on the query parameters\"\"\"\n",
    "    BASE_URL = 'https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi'\n",
    "    param_dict = {\n",
    "        \"BBOX\": bbox,\n",
    "        \"CRS\": \"EPSG:4326\",\n",
    "        \"FORMAT\": \"image/jpeg\",\n",
    "        \"HEIGHT\": height,\n",
    "        \"LAYERS\": \"MODIS_%s_CorrectedReflectance_%s\" % (sensor, product),\n",
    "        \"REQUEST\": \"GetMap\",\n",
    "        \"SERVICE\": \"WMS\",\n",
    "        \"TIME\": query_date,\n",
    "        \"TRANSPARENT\": \"false\",\n",
    "        \"VERSION\": \"1.3.0\",\n",
    "        \"WIDTH\": width,\n",
    "    }\n",
    "\n",
    "    return \"{}?{}\".format(BASE_URL, urlencode(param_dict))\n",
    "\n",
    "\n",
    "def calculate_width_height(extent, resolution):\n",
    "    \"\"\"\n",
    "    extent: [lower_latitude, left_longitude, higher_latitude, right_longitude], EG: [51.46162974683544,-22.94768591772153,53.03698575949367,-20.952234968354432]\n",
    "    resolution: represents the pixel resolution, i.e. km/pixel. Should be a value from this list: [0.03, 0.06, 0.125, 0.25, 0.5, 1, 5, 10]\n",
    "    \"\"\"\n",
    "    lats = extent[::2]\n",
    "    lons = extent[1::2]\n",
    "    km_per_deg_at_lat = KM_PER_DEG_AT_EQ * np.cos(np.pi * np.mean(lats) / 180.)\n",
    "    width = int((lons[1] - lons[0]) * km_per_deg_at_lat / resolution)\n",
    "    height = int((lats[1] - lats[0]) * KM_PER_DEG_AT_EQ / resolution)\n",
    "    return (width, height)\n",
    "\n",
    "\n",
    "def modis_url(time, extent, resolution):\n",
    "    \"\"\"\n",
    "    time: utc time in iso format EG: 2020-02-19T00:00:00Z\n",
    "    extent: [lower_latitude, left_longitude, higher_latitude, right_longitude], EG: [51.46162974683544,-22.94768591772153,53.03698575949367,-20.952234968354432]\n",
    "    resolution: represents the pixel resolution, i.e. km/pixel. Should be a value from this list: [0.03, 0.06, 0.125, 0.25, 0.5, 1, 5, 10]\n",
    "    \"\"\"\n",
    "    width, height = calculate_width_height(extent, resolution)\n",
    "    extent = ','.join(map(lambda x: str(x), extent))\n",
    "    return (width, height, URL.format(width, height, extent, time))\n",
    "\n",
    "\n",
    "def bitmap_from_shp(fiona_shape, transform, img_shape, filename):\n",
    "    \"\"\" extract out the smoke pixels using the shapefile\n",
    "     from the transform defined\n",
    "    Args:\n",
    "        fiona_shape (Collection): fiona shape collection obtained by fiona.open()\n",
    "        transfrom (rasterio.transfrom.Affine): rasterio transform object\n",
    "    \"\"\"\n",
    "    geoms = []\n",
    "    y_mtx = np.zeros((img_shape))\n",
    "    for shape in fiona_shape:\n",
    "        geoms.append(shape[\"geometry\"])\n",
    "    bitmap_filename = filename.replace('.shp', '_bitmap.png')\n",
    "    # raster the geoms onto a bitmap\n",
    "    geom_map = [(geo, 255) for geo in geoms]\n",
    "    y_mtx = rasterio.features.rasterize(\n",
    "        geom_map,\n",
    "        out_shape=(img_shape[1], img_shape[0]),\n",
    "        transform=transform\n",
    "    )\n",
    "    img = Image.fromarray(y_mtx)\n",
    "    print(f\"Preparing Bitmap: {filename}\")\n",
    "    img.save(f\"{DATA_FOLDER}/{IMAGE_FOLDER}/{bitmap_filename}\")\n",
    "    \n",
    "\n",
    "def explode(coords):\n",
    "    \"\"\"\n",
    "    Explode a GeoJSON geometry's coordinates object and yield coordinate tuples.\n",
    "    As long as the input is conforming, the type of the geometry doesn't matter.\n",
    "    \"\"\"\n",
    "    for e in coords:\n",
    "        if isinstance(e, (float, int)):\n",
    "            yield coords\n",
    "            break\n",
    "        else:\n",
    "            for f in explode(e):\n",
    "                yield f\n",
    "\n",
    "\n",
    "def extract_bbox(fiona_shape, offset=0):\n",
    "    \"\"\"\n",
    "    Extract bounding box from shapefile\n",
    "    \"\"\"\n",
    "    x, y = zip(*list(explode(fiona_shape['geometry']['coordinates'])))\n",
    "    return min(y) - offset, min(x) - offset, max(y) + offset, max(x) + offset\n",
    "\n",
    "\n",
    "def download_image(date, bounding_box, shapefile_name):\n",
    "    \"\"\"\n",
    "    Download images from gibs (https://earthdata.nasa.gov/eosdis/science-system-description/eosdis-components/gibs)\n",
    "    date: date of event\n",
    "    bounding_box: [lower_latitude, left_longitude, higher_latitude, right_longitude], EG: [51.46162974683544,-22.94768591772153,53.03698575949367,-20.952234968354432]\n",
    "    \"\"\"\n",
    "    resolution = RESOLUTION\n",
    "    width, height, url = modis_url(date, bounding_box, RESOLUTION)\n",
    "    print(url)\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    file_name = shapefile_name.replace('shp', 'tiff')\n",
    "    file_name = f\"{DATA_FOLDER}/{IMAGE_FOLDER}/{file_name}\"\n",
    "    print(f\"Downloading Image: {file_name}\")\n",
    "    with open(file_name, 'wb') as img_file:\n",
    "        img_file.write(response.content)\n",
    "    return width, height, file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training, Validation and Test Splits\n",
    "\n",
    "While Training a ML model, The danger in the training process is that your model may overfit to the training set. That is, the model might learn an overly specific function that performs well on your training data, but does not generalize to images it has never seen. This is called Overfitting.\n",
    "\n",
    "The train, validation, and testing splits are built to combat overfitting.\n",
    "\n",
    "\n",
    "### Train Split\n",
    "The training set the largest corpus of your dataset that you reserve for training your model. After training, inference on these images will be taken with a grain of salt, since the model has already had a chance to look at and memorize the correct output.\n",
    "\n",
    "### Validation Split\n",
    "The validation set is a separate section of your dataset that you will use during training to get a sense of how well your model is doing on images that are not being used in training.\n",
    "\n",
    "### Test Split\n",
    "After all of the training experiments have concluded, you probably have gotten a sense on how your model might do on the validation set. But it is important to remember that the validation set metrics may have influenced you during the creation of the model, and in this sense you might, as a designer, overfit the new model to the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split(split, files):\n",
    "    \"\"\"\n",
    "    Clear and create folder with new files.\n",
    "    split: choice of \"train\", \"test\", and \"val\"\n",
    "    files: list of tiff file paths\n",
    "\n",
    "    \"\"\"\n",
    "    print(f'Preparing {split} split with {len(files)} examples.')\n",
    "    folder_name = f\"{DATA_FOLDER}/{split}\"\n",
    "    if os.path.exists(folder_name):\n",
    "        delete_folder(folder_name)\n",
    "    mkdir(folder_name)\n",
    "    for filename in files:\n",
    "        internal_filename = filename.split('/')[-1]\n",
    "        bitmap_filename = filename.replace('.tiff', '_bitmap.png')\n",
    "        shutil.copyfile(filename, f\"{folder_name}/{internal_filename}\")\n",
    "        shutil.copyfile(bitmap_filename, f\"{folder_name}/{bitmap_filename.split('/')[-1]}\")\n",
    "         \n",
    "# prepare train, val, and test splits\n",
    "def prepare_splits(source_folder, splits={'train': 0.6, 'val': 0.2, 'test': 0.2}):\n",
    "    \"\"\" Creates training, validation and test splits from `source folder`\n",
    "    \"\"\"\n",
    "    files = glob(f\"{source_folder}/*.tiff\")\n",
    "    print(f\"Total examples found: {len(files)}\")\n",
    "    random.shuffle(files)\n",
    "    length = len(files)\n",
    "    train_limit = math.ceil(length * splits['train'])\n",
    "    val_limit = train_limit + math.ceil(length * splits['train'])\n",
    "    create_split('train', files[0:train_limit])\n",
    "    create_split('val', files[train_limit:val_limit])\n",
    "    create_split('test', files[train_limit:val_limit])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download shapefiles from S3 bucket and images from WorldView\n",
    "- This function downloads the shapefiles that we previously labeled using imagelabeler.\n",
    "- The date-time and bounds of the shapefiles are found and the corresponding GIBS imagery is downloaded\n",
    "- The shapefiles are converted into bitmaps, which will serve as training labels.\n",
    "- The Images are finally stored in `DATA_FOLDER`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(boto_session):\n",
    "    \"\"\"\n",
    "    Download and prepare images from available shapefiles\n",
    "    boto_session: Boto session currently in use.\n",
    "    \"\"\"\n",
    "    s3_connection = boto_session.resource('s3')\n",
    "    bucket = s3_connection.Bucket(SOURCE_BUCKET)\n",
    "    objects = list(bucket.objects.filter(Prefix=f\"hld/\"))\n",
    "    foldername = f\"{DATA_FOLDER}/{SHAPEFILE_FOLDER}\"\n",
    "    mkdir(foldername)\n",
    "    for iter_object in objects:\n",
    "        print(iter_object.key)\n",
    "        splits = iter_object.key.split('/')\n",
    "        local_foldername = f\"{foldername}/{splits[1]}\"\n",
    "        mkdir(local_foldername)\n",
    "        filename = f\"{local_foldername}/{splits[-1]}\"\n",
    "        if not(os.path.exists(filename)):\n",
    "            bucket.download_file(iter_object.key, filename)\n",
    "        else: \n",
    "            print(f\"File already exists. {filename}\")\n",
    "    mkdir(f\"{DATA_FOLDER}/{IMAGE_FOLDER}\")\n",
    "    for shapefilename in glob(f\"{foldername}/*/*.shp\"):\n",
    "        date = shapefilename.split('_')[1]\n",
    "        filename = shapefilename.split('/')[-1]\n",
    "        with fiona.open(shapefilename, \"r\") as shapefile:\n",
    "            bounds = shapefile.bounds\n",
    "            bounds = [bounds[1], bounds[0], bounds[3], bounds[2]]\n",
    "            width, height, image_filename = download_image(date, bounds, filename)\n",
    "            try:\n",
    "                with rasterio.open(image_filename) as src:\n",
    "                    bitmap_from_shp(shapefile, src.transform, (width, height), filename)\n",
    "            except:\n",
    "                print(f\"Unable to download file: {image_filename}\")\n",
    "                os.remove(image_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download processed images that are stored in the s3 bucket, incase the above processing step fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(boto_session):\n",
    "    \"\"\"\n",
    "    Download and store data in folders.\n",
    "    boto_session: Boto session currently in use.\n",
    "    \"\"\"\n",
    "    s3_connection = session.resource('s3')\n",
    "    bucket = s3_connection.Bucket(SOURCE_BUCKET)\n",
    "    objects = list(bucket.objects.filter(Prefix=f\"{EVENT}/\"))\n",
    "    foldername = f\"{DATA_FOLDER}/{IMAGE_FOLDER}\"\n",
    "    mkdir(foldername)\n",
    "    for iter_object in objects:\n",
    "        print(iter_object.key)\n",
    "        splits = iter_object.key.split('/')\n",
    "        if splits[-1]:\n",
    "            filename = f\"{foldername}/{splits[-1]}\"\n",
    "            bucket.download_file(iter_object.key, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together - Creating a session with permissions to preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = assumed_role_session()  # Create a aws session with appropriate permissions\n",
    "# prepare_datasets(session) # preprocess shapefiles and images to ML ready format \n",
    "download_dataset(session) # download preprocessed dataset\n",
    "prepare_splits(f\"{DATA_FOLDER}/{IMAGE_FOLDER}\")  # create splits for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(num_samples=5):\n",
    "    \"\"\" Samples 'num_samples' # of test datasets from the test data split,\n",
    "    returns the images and the labels\n",
    "    \"\"\"\n",
    "    test_array = []\n",
    "    bmp_array = []\n",
    "    all_images = glob('data/test/*.tif*')\n",
    "    random.shuffle(all_images)\n",
    "    test_images_sampled = all_images[:num_samples]\n",
    "    for test_image in test_images_sampled:\n",
    "        image = cv2.imread(test_image)\n",
    "        bmp_image = cv2.imread(test_image.replace('.tiff','_bitmap.png'))\n",
    "        test_array.append(image)\n",
    "        bmp_array.append(bmp_image)\n",
    "    return test_array, bmp_array\n",
    "\n",
    "modis_batch, bmp_batch = get_test_data()\n",
    "\n",
    "for j in range(len(modis_batch)):\n",
    "    bmp_data = bmp_batch[j]\n",
    "    f, ax = plt.subplots(1, 2, constrained_layout=True, dpi=100)\n",
    "    ax[0].imshow(modis_batch[j].astype('uint8'))\n",
    "    ax[0].set_title('RGB Image')\n",
    "    ax[0].xaxis.set_ticks([])\n",
    "    ax[0].yaxis.set_ticks([])\n",
    "    ax[1].imshow(modis_batch[j].astype('uint8'))\n",
    "    ax[1].xaxis.set_ticks([])\n",
    "    ax[1].yaxis.set_ticks([])\n",
    "    ax[1].set_title('SME label overlay')\n",
    "    ax[1].imshow(ma.masked_where(bmp_data != 0, bmp_data)[:,:,0],alpha=0.35,cmap='Purples')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "b2f39e33ffaae589a3831cb10b63d3db471aae6fe85e5b0ac435826ecc22d42b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
