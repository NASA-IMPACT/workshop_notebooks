{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and understand the data in hand\n",
    "\n",
    "A subset of High Latitude Dust data is pre-prepared and uploaded into a s3 bucket (impact-datashare). The details can be found at https://github.com/nasa-impact/data_share ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../chapter-3/src/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import fiona\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import rasterio.features\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from io import BytesIO\n",
    "from IPython.display import Image as Display\n",
    "from PIL import Image\n",
    "from rasterio.warp import calculate_default_transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Constant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_NUMBER = \"350996086543\"\n",
    "ROLE_NAME = \"notebookAccessRole\"\n",
    "ROLE_ARN = f\"arn:aws:iam::{ACCOUNT_NUMBER}:role/{ROLE_NAME}\"\n",
    "SOURCE_BUCKET = \"impact-datashare\"\n",
    "DESTINATION_BUCKET = \"<your bucket name>\"\n",
    "\n",
    "# NOTE: Use image_url function above to create a valid url, if the shapefile generation was not done in Aqua, TrueColor \n",
    "DATA_FOLDER = \"data\"\n",
    "EVENT = \"hld-labeled\"\n",
    "IMAGE_FOLDER = \"images\"\n",
    "SHAPEFILE_FOLDER = \"shapefiles\"\n",
    "URL = \"https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi?SERVICE=WMS&REQUEST=GetMap&layers=MODIS_Aqua_CorrectedReflectance_TrueColor&version=1.3.0&crs=EPSG:4326&transparent=false&width={}&height={}&bbox={}&format=image/tiff&time={}\"\n",
    "KM_PER_DEG_AT_EQ = 111.\n",
    "RESOLUTION = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment for data transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assumed_role_session():\n",
    "    # Assume the \"notebookAccessRole\" role we created using AWS CDK.\n",
    "    client = boto3.client('sts')\n",
    "    creds = client.assume_role(\n",
    "        RoleArn=ROLE_ARN,\n",
    "        RoleSessionName=ROLE_NAME\n",
    "    )['Credentials']\n",
    "    return boto3.session.Session(\n",
    "        aws_access_key_id=creds['AccessKeyId'],\n",
    "        aws_secret_access_key=creds['SecretAccessKey'],\n",
    "        aws_session_token=creds['SessionToken'],\n",
    "        region_name='us-east-1'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods to download and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(foldername):\n",
    "    if os.path.exists(foldername):\n",
    "        print(f\"'{foldername}' folder already exists.\")\n",
    "        return\n",
    "    os.makedirs(foldername)\n",
    "    print(f\"Created folder: {foldername}\")\n",
    "\n",
    "    \n",
    "def delete_folder(foldername):\n",
    "    if os.path.exists(foldername):\n",
    "        shutil.rmtree(foldername) \n",
    "    else:\n",
    "        print(f\"Folder {foldername} doesn't exist.\")\n",
    "    \n",
    "    \n",
    "# use this if you are using anything else than Aqua and TrueColor to generate the image in the image labeler\n",
    "def image_url(query_date, bbox, sensor, product, width, height):\n",
    "    BASE_URL = 'https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi'\n",
    "    param_dict = {\n",
    "        \"BBOX\": bbox,\n",
    "        \"CRS\": \"EPSG:4326\",\n",
    "        \"FORMAT\": \"image/jpeg\",\n",
    "        \"HEIGHT\": height,\n",
    "        \"LAYERS\": \"MODIS_%s_CorrectedReflectance_%s\" % (sensor, product),\n",
    "        \"REQUEST\": \"GetMap\",\n",
    "        \"SERVICE\": \"WMS\",\n",
    "        \"TIME\": query_date,\n",
    "        \"TRANSPARENT\": \"false\",\n",
    "        \"VERSION\": \"1.3.0\",\n",
    "        \"WIDTH\": width,\n",
    "    }\n",
    "\n",
    "    return \"{}?{}\".format(BASE_URL, urlencode(param_dict))\n",
    "\n",
    "\n",
    "def calculate_width_height(extent, resolution):\n",
    "    \"\"\"\n",
    "    extent: [lower_latitude, left_longitude, higher_latitude, right_longitude], EG: [51.46162974683544,-22.94768591772153,53.03698575949367,-20.952234968354432]\n",
    "    resolution: represents the pixel resolution, i.e. km/pixel. Should be a value from this list: [0.03, 0.06, 0.125, 0.25, 0.5, 1, 5, 10]\n",
    "    \"\"\"\n",
    "    lats = extent[::2]\n",
    "    lons = extent[1::2]\n",
    "    km_per_deg_at_lat = KM_PER_DEG_AT_EQ * np.cos(np.pi * np.mean(lats) / 180.)\n",
    "    width = int((lons[1] - lons[0]) * km_per_deg_at_lat / resolution)\n",
    "    height = int((lats[1] - lats[0]) * KM_PER_DEG_AT_EQ / resolution)\n",
    "    return (width, height)\n",
    "\n",
    "\n",
    "def modis_url(time, extent, resolution):\n",
    "    \"\"\"\n",
    "    time: utc time in iso format EG: 2020-02-19T00:00:00Z\n",
    "    extent: [lower_latitude, left_longitude, higher_latitude, right_longitude], EG: [51.46162974683544,-22.94768591772153,53.03698575949367,-20.952234968354432]\n",
    "    resolution: represents the pixel resolution, i.e. km/pixel. Should be a value from this list: [0.03, 0.06, 0.125, 0.25, 0.5, 1, 5, 10]\n",
    "    \"\"\"\n",
    "    width, height = calculate_width_height(extent, resolution)\n",
    "    extent = ','.join(map(lambda x: str(x), extent))\n",
    "    return (width, height, URL.format(width, height, extent, time))\n",
    "\n",
    "\n",
    "def bitmap_from_shp(fiona_shape, transform, img_shape, filename):\n",
    "    \"\"\" extract out the smoke pixels using the shapefile\n",
    "     from the transform defined\n",
    "    Args:\n",
    "        fiona_shape (Collection): fiona shape collection obtained by fiona.open()\n",
    "        transfrom (rasterio.transfrom.Affine): rasterio transform object\n",
    "    \"\"\"\n",
    "    geoms = []\n",
    "    y_mtx = np.zeros((img_shape))\n",
    "    for shape in fiona_shape:\n",
    "        geoms.append(shape[\"geometry\"])\n",
    "    bitmap_filename = filename.replace('.shp', '_bitmap.png')\n",
    "    # raster the geoms onto a bitmap\n",
    "    geom_map = [(geo, 255) for geo in geoms]\n",
    "    y_mtx = rasterio.features.rasterize(\n",
    "        geom_map,\n",
    "        out_shape=(img_shape[0], img_shape[1]),\n",
    "        transform=transform\n",
    "    )\n",
    "    img = Image.fromarray(y_mtx)\n",
    "    print(f\"Preparing Bitmap: {filename}\")\n",
    "    img.save(f\"{DATA_FOLDER}/{IMAGE_FOLDER}/{bitmap_filename}\")\n",
    "    \n",
    "\n",
    "def explode(coords):\n",
    "    \"\"\"\n",
    "    Explode a GeoJSON geometry's coordinates object and yield coordinate tuples.\n",
    "    As long as the input is conforming, the type of the geometry doesn't matter.\n",
    "    \"\"\"\n",
    "    for e in coords:\n",
    "        if isinstance(e, (float, int)):\n",
    "            yield coords\n",
    "            break\n",
    "        else:\n",
    "            for f in explode(e):\n",
    "                yield f\n",
    "\n",
    "\n",
    "def extract_bbox(fiona_shape, offset=0):\n",
    "    \"\"\"\n",
    "    Extract bounding box from shapefile\n",
    "    \"\"\"\n",
    "    x, y = zip(*list(explode(fiona_shape['geometry']['coordinates'])))\n",
    "    return min(y) - offset, min(x) - offset, max(y) + offset, max(x) + offset\n",
    "\n",
    "\n",
    "def download_image(date, bounding_box, shapefile_name):\n",
    "    \"\"\"\n",
    "    Download images from gibs\n",
    "    date: date of event\n",
    "    bounding_box: [lower_latitude, left_longitude, higher_latitude, right_longitude], EG: [51.46162974683544,-22.94768591772153,53.03698575949367,-20.952234968354432]\n",
    "    \"\"\"\n",
    "    resolution = RESOLUTION\n",
    "    width, height, url = modis_url(date, bounding_box, RESOLUTION)\n",
    "    print(url)\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    file_name = shapefile_name.replace('shp', 'tiff')\n",
    "    file_name = f\"{DATA_FOLDER}/{IMAGE_FOLDER}/{file_name}\"\n",
    "    print(f\"Downloading Image: {file_name}\")\n",
    "    with open(file_name, 'wb') as img_file:\n",
    "        img_file.write(response.content)\n",
    "    return width, height, file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove already existing folder for a split and create a new one with passed filenames\n",
    "def create_split(split, files):\n",
    "    \"\"\"\n",
    "    Clear and create folder with new files.\n",
    "    split: choice of \"train\", \"test\", and \"val\"\n",
    "    files: list of tiff file paths\n",
    "    \"\"\"\n",
    "    print(f'Preparing {split} split with {len(files)} examples.')\n",
    "    folder_name = f\"{DATA_FOLDER}/{split}\"\n",
    "    if os.path.exists(folder_name):\n",
    "        delete_folder(folder_name)\n",
    "    mkdir(folder_name)\n",
    "    for filename in files:\n",
    "        internal_filename = filename.split('/')[-1]\n",
    "        bitmap_filename = filename.replace('.tiff', '_bitmap.png')\n",
    "        shutil.copyfile(filename, f\"{folder_name}/{internal_filename}\")\n",
    "        shutil.copyfile(bitmap_filename, f\"{folder_name}/{bitmap_filename.split('/')[-1]}\")\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train, val, and test splits\n",
    "def prepare_splits(source_folder, splits={'train': 0.6, 'val': 0.2, 'test': 0.2}):\n",
    "    files = glob(f\"{source_folder}/*.tiff\")\n",
    "    print(f\"Total examples found: {len(files)}\")\n",
    "    random.shuffle(files)\n",
    "    length = len(files)\n",
    "    train_limit = math.ceil(length * splits['train'])\n",
    "    val_limit = train_limit + math.ceil(length * splits['train'])\n",
    "    create_split('train', files[0:train_limit])\n",
    "    create_split('val', files[train_limit:val_limit])\n",
    "    create_split('test', files[train_limit:val_limit])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download shapefiles from S3 bucket and images from WorldView.\n",
    "def download_dataset(boto_session):\n",
    "    \"\"\"\n",
    "    Download and store data in folders.\n",
    "    \"\"\"\n",
    "    s3_connection = session.resource('s3')\n",
    "    bucket = s3_connection.Bucket(SOURCE_BUCKET)\n",
    "    objects = list(bucket.objects.filter(Prefix=f\"{EVENT}/\"))\n",
    "    foldername = f\"{DATA_FOLDER}/{IMAGE_FOLDER}\"\n",
    "    mkdir(foldername)\n",
    "    for iter_object in objects:\n",
    "        print(iter_object.key)\n",
    "        splits = iter_object.key.split('/')\n",
    "        if splits[-1]:\n",
    "            filename = f\"{foldername}/{splits[-1]}\"\n",
    "            bucket.download_file(iter_object.key, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(boto_session):\n",
    "    \"\"\"\n",
    "    Download and prepare images from available shapefiles\n",
    "    boto_session: Boto session currently in use.\n",
    "    \"\"\"\n",
    "    s3_connection = session.resource('s3')\n",
    "    bucket = s3_connection.Bucket(SOURCE_BUCKET)\n",
    "    objects = list(bucket.objects.filter(Prefix=f\"hld/\"))\n",
    "    foldername = f\"{DATA_FOLDER}/{SHAPEFILE_FOLDER}\"\n",
    "    mkdir(foldername)\n",
    "    for iter_object in objects:\n",
    "        print(iter_object.key)\n",
    "        splits = iter_object.key.split('/')\n",
    "        local_foldername = f\"{foldername}/{splits[1]}\"\n",
    "        mkdir(local_foldername)\n",
    "        filename = f\"{local_foldername}/{splits[-1]}\"\n",
    "        if not(os.path.exists(filename)):\n",
    "            bucket.download_file(iter_object.key, filename)\n",
    "        else: \n",
    "            print(f\"File already exists. {filename}\")\n",
    "    mkdir(f\"{DATA_FOLDER}/{IMAGE_FOLDER}\")\n",
    "    for shapefilename in glob(f\"{foldername}/*/*.shp\"):\n",
    "        date = shapefilename.split('_')[1]\n",
    "        filename = shapefilename.split('/')[-1]\n",
    "        with fiona.open(shapefilename, \"r\") as shapefile:\n",
    "            bounds = shapefile.bounds\n",
    "            bounds = [bounds[1], bounds[0], bounds[3], bounds[2]]\n",
    "            width, height, image_filename = download_image(date, bounds, filename)\n",
    "            try:\n",
    "                with rasterio.open(image_filename) as src:\n",
    "                    bitmap_from_shp(shapefile, src.transform, (width, height), filename)\n",
    "            except:\n",
    "                print(f\"Unable to download file: {image_filename}\")\n",
    "                os.remove(image_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = assumed_role_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prepare_datasets(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dataset(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_splits(f\"{DATA_FOLDER}/{IMAGE_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp data ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
